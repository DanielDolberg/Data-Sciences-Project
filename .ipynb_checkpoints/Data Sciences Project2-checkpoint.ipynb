{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67c0f6df-3e4e-415a-8375-5d3b8ac2155b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Sciences Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bceab18b-19d2-41a3-ba2a-2191b8b401dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install selenium\n",
    "\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import clear_output #library that clears a cell's outputs\n",
    "\n",
    "import sklearn\n",
    "from sklearn import linear_model, metrics, preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import r2_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d3e28-3bee-487f-b2d6-848ce3b45001",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754041f8-a3d8-448d-856f-13a0d6b3e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addData(arr,data):\n",
    "    try:\n",
    "        arr.append(data.find_element(By.CLASS_NAME,\"value\").text)\n",
    "    except:\n",
    "        arr.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cded2a-2f34-40a4-949b-7de9fcce9169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addCTBar(arr,data):\n",
    "    try:\n",
    "        arr.append(data.get_attribute(\"ct:value\"))\n",
    "    except:\n",
    "        arr.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d7f9d68-c631-4769-a080-c98cdd69c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addText(arr,data):\n",
    "    try:\n",
    "        arr.append(data.text)\n",
    "    except:\n",
    "        arr.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2df246-83bc-4773-a801-786474512153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_In_List(arr,word):\n",
    "    for t in range(len(arr)):\n",
    "        if (arr[t] == word):\n",
    "            #print(word)\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae432e2-5c89-44ea-a6cb-cd64c08c0554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def has_anime(lst):\n",
    "    try:\n",
    "        tst = lst.split(' ')\n",
    "        if (((tst[0] == \"TV\") or (tst[0] == \"Movie\") or (tst[0] == \"OVA\") or (tst[0] == \"ONA\") or (tst[0] == \"Special\")) and ((tst[2] == \"Finished\") or (tst[2] == \"Releasing\"))):\n",
    "            return True\n",
    "        else: return False\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49e69b3-3aca-4617-957f-ffd0aacdf9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anime_date(link):\n",
    "    \n",
    "    drv = webdriver.Chrome()\n",
    "    drv.get(link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    data = drv.find_elements(By.CLASS_NAME,\"data-set\")\n",
    "    \n",
    "    for d in data:\n",
    "        \n",
    "        dstr = d.find_element(By.CLASS_NAME,\"type\").text\n",
    "        #print(dstr)\n",
    "        \n",
    "        if ((dstr == \"Start Date\") or (dstr == \"Release Date\")):\n",
    "            txt = d.find_element(By.CLASS_NAME,\"value\").text\n",
    "            rtxt = [int(s) for s in txt.split() if s.isdigit()][0]\n",
    "            return rtxt\n",
    "    return np.nan\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09afa4a-776b-4dda-912a-48025f97c750",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f944e36-10f1-468f-b200-b4ce9db08803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = \"\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://anilist.co/search/manga?format=NOVEL\")\n",
    "driver.maximize_window();\n",
    "\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06658c14-015b-4afc-9390-2c095377c872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6860\n"
     ]
    }
   ],
   "source": [
    "for j in range(1500):\n",
    "    driver.execute_script(\"window.scrollTo(0,\" + str(j * 1000) + \");\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "links = driver.find_elements(By.CLASS_NAME,\"media-card\")\n",
    "link_list = [elem.find_element(By.CLASS_NAME,\"cover\").get_attribute('href') for elem in links]\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(len(link_list))#length of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ef3f3e-d275-4d5b-9e46-d7856d719ff4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_into_df(link,tempdrive):\n",
    "    tempdrive.get(link)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #init dataset element list\n",
    "    try:\n",
    "        dataset = tempdrive.find_elements(By.CLASS_NAME,\"data-set\")\n",
    "    except:\n",
    "        dataset = []\n",
    "    \n",
    "    \n",
    "    #init ctbar element list\n",
    "    try:\n",
    "        ctbar = tempdrive.find_element(By.CLASS_NAME,\"grid-section-wrap\").find_elements(By.TAG_NAME,\"g\")[2].find_elements(By.CLASS_NAME,\"ct-bar\")#.get_attribute(\"ct:value\")\n",
    "    except:\n",
    "        ctbar = []\n",
    "        \n",
    "    try:\n",
    "        ctlabels = tempdrive.find_element(By.CLASS_NAME,\"grid-section-wrap\").find_element(By.CLASS_NAME,\"ct-labels\").find_elements(By.XPATH,\"//span[contains(@class,'ct-label ct-horizontal ct-end')]\")\n",
    "    except:\n",
    "        ctlabels = []\n",
    "    \n",
    "    #init rankings element list\n",
    "    try:\n",
    "        ranku = tempdrive.find_element(By.CLASS_NAME,\"rankings\").find_elements(By.CLASS_NAME,\"rank-text\")\n",
    "    except:\n",
    "        ranku = []\n",
    "    \n",
    "    \n",
    "    #init tags element list\n",
    "    try:\n",
    "        tagspoilclick = tempdrive.find_element(By.CLASS_NAME,\"spoiler-toggle\")\n",
    "        tagspoilclick.click()\n",
    "        taglist = tempdrive.find_elements(By.CSS_SELECTOR,\".el-tooltip.name\")\n",
    "    except:\n",
    "        tagspolclick = []\n",
    "        taglist = []\n",
    "    \n",
    "    \n",
    "    #init relations element list\n",
    "    try:\n",
    "        pcell = tempdrive.find_element(By.CLASS_NAME,\"relations\").find_elements(By.CLASS_NAME,\"media-preview-card\")\n",
    "    except:\n",
    "        pcell = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    #help with skipped ctbar nums\n",
    "    ctbarcount = 0\n",
    "    \n",
    "    #check if english name exists\n",
    "    engFlag = True\n",
    "    \n",
    "    \n",
    "    #dataset element features\n",
    "    format_ = []\n",
    "    chap_ = []\n",
    "    vol_ = []\n",
    "    status_ = []\n",
    "    start_ = []\n",
    "    end_ = []\n",
    "    avg_score_ = []\n",
    "    mean_score_ = []\n",
    "    pop_ = []\n",
    "    favs_ = []\n",
    "    source_ = []\n",
    "    genres_ = []\n",
    "    name_romaj_ = []\n",
    "    name_eng_ = []\n",
    "    name_native_ = []\n",
    "    name_synon_ = []\n",
    "    release_year = []\n",
    "    \n",
    "    #dataset feature flags\n",
    "    format_Flag = False\n",
    "    chap_Flag = False\n",
    "    vol_Flag = False\n",
    "    status_Flag = False\n",
    "    start_Flag = False\n",
    "    end_Flag = False\n",
    "    avg_score_Flag = False\n",
    "    mean_score_Flag = False\n",
    "    pop_Flag = False\n",
    "    favs_Flag = False\n",
    "    source_Flag = False\n",
    "    genres_Flag = False\n",
    "    name_romaj_Flag = False\n",
    "    name_eng_Flag = False\n",
    "    name_native_Flag = False\n",
    "    name_synon_Flag = False\n",
    "    \n",
    "    \n",
    "    #ctbar element features\n",
    "    rating_10 = []\n",
    "    rating_20 = []\n",
    "    rating_30 = []\n",
    "    rating_40 = []\n",
    "    rating_50 = []\n",
    "    rating_60 = []\n",
    "    rating_70 = []\n",
    "    rating_80 = []\n",
    "    rating_90 = []\n",
    "    rating_100 = []\n",
    "    \n",
    "    #ctbar element flags\n",
    "    rating_10_Flag = False\n",
    "    rating_20_Flag = False\n",
    "    rating_30_Flag = False\n",
    "    rating_40_Flag = False\n",
    "    rating_50_Flag = False\n",
    "    rating_60_Flag = False\n",
    "    rating_70_Flag = False\n",
    "    rating_80_Flag = False\n",
    "    rating_90_Flag = False\n",
    "    rating_100_Flag = False\n",
    "    \n",
    "    #rankings element features\n",
    "    rated_rank = []\n",
    "    popul_rank = []\n",
    "    ratenum = []\n",
    "    populnum = []\n",
    "    \n",
    "    #relations element features\n",
    "\n",
    "    cell1_type = []\n",
    "\n",
    "    cell2_type = []\n",
    "    \n",
    "    relations_types = []\n",
    "    \n",
    "    has_anime_ = []\n",
    "    anime_Flag = False\n",
    "    \n",
    "    anime_rls_date = []\n",
    "\n",
    "    #Genres\n",
    "    gen_one = []\n",
    "    gen_two = []\n",
    "    gen_thr = []\n",
    "    \n",
    "    #Tags\n",
    "    tag_one = []\n",
    "    tag_two = []\n",
    "    tag_thr = []\n",
    "    \n",
    "    #Weird feature but let's try\n",
    "    name_word_count = []\n",
    "    \n",
    "    #Gotta save links\n",
    "    links_ = []\n",
    "\n",
    "    \n",
    "    \n",
    "    #Check and Handle appending of dataset features\n",
    "    \n",
    "    for p in dataset:\n",
    "        \n",
    "        testStr = p.find_element(By.CLASS_NAME,\"type\").text\n",
    "        \n",
    "        if ((testStr == \"Format\") & (format_Flag == False)):\n",
    "            format_Flag = True\n",
    "            try:\n",
    "                addData(format_,p)\n",
    "            except:\n",
    "                format_.append(np.nan)\n",
    "        \n",
    "        if ((testStr == \"Chapters\") & (chap_Flag == False)):\n",
    "            chap_Flag = True\n",
    "            try:\n",
    "                addData(chap_,p)\n",
    "            except:\n",
    "                chap_.append(np.nan)\n",
    "        \n",
    "        if ((testStr == \"Volumes\") & (vol_Flag == False)):\n",
    "            vol_Flag = True\n",
    "            try:\n",
    "                addData(vol_,p)\n",
    "            except:\n",
    "                vol_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Status\") & (status_Flag == False)):\n",
    "            status_Flag = True\n",
    "            try:\n",
    "                addData(status_,p)\n",
    "            except:\n",
    "                status_.append(np.nan)\n",
    "        \n",
    "        if (((testStr == \"Start Date\") or (testStr == \"Release Date\")) & (start_Flag == False)):\n",
    "            start_Flag = True\n",
    "            try:\n",
    "                addData(start_,p)\n",
    "            except:\n",
    "                start_.append(np.nan)\n",
    "        \n",
    "        if ((testStr == \"End Date\") & (end_Flag == False)):\n",
    "            end_Flag = True\n",
    "            try:\n",
    "                addData(end_,p)\n",
    "            except:\n",
    "                end_.append('TBD')\n",
    "            \n",
    "        if ((testStr == \"Average Score\") & (avg_score_Flag == False)):\n",
    "            avg_score_Flag = True\n",
    "            try:\n",
    "                avg_score_temp = []\n",
    "                addData(avg_score_temp,p)\n",
    "                avg_score_.append(avg_score_temp[0].split('%')[0])\n",
    "            except:\n",
    "                avg_score_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Mean Score\") & (mean_score_Flag == False)):\n",
    "            mean_score_Flag = True\n",
    "            try:\n",
    "                mean_score_temp = []\n",
    "                addData(mean_score_temp,p)\n",
    "                mean_score_.append(mean_score_temp[0].split('%')[0])\n",
    "            except:\n",
    "                mean_score_.append(np.nan)\n",
    "                \n",
    "        if ((testStr == \"Popularity\") & (pop_Flag == False)):\n",
    "            pop_Flag = True\n",
    "            try:    \n",
    "                addData(pop_,p)\n",
    "            except:\n",
    "                pop_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Favorites\") & (favs_Flag == False)):\n",
    "            favs_Flag = True\n",
    "            try:\n",
    "                addData(favs_,p)\n",
    "            except:\n",
    "                favs_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Source\") & (source_Flag == False)):\n",
    "            source_Flag = True\n",
    "            try:\n",
    "                addData(source_,p)\n",
    "            except:\n",
    "                source_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Genres\") & (genres_Flag == False)):\n",
    "            genres_Flag = True\n",
    "            try:\n",
    "                addData(genres_,p)\n",
    "            except:\n",
    "                genres_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Romaji\") & (name_romaj_Flag == False)):\n",
    "            name_romaj_Flag = True\n",
    "            try:\n",
    "                addData(name_romaj_,p)\n",
    "            except:\n",
    "                name_romaj_.append(np.nan)\n",
    "        \n",
    "        if ((testStr == \"English\") & (name_eng_Flag == False)):\n",
    "            name_eng_Flag = True\n",
    "            try:\n",
    "                if (p.find_element(By.CLASS_NAME,\"type\").text == \"English\"):\n",
    "                    addData(name_eng_,p)\n",
    "                else:\n",
    "                    engFlag = False\n",
    "                    #print(engFlag)\n",
    "                    name_eng.append(np.nan)\n",
    "            except:\n",
    "                name_eng_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Native\") & (name_native_Flag == False)):\n",
    "            name_native_Flag = True\n",
    "            try:\n",
    "                if (engFlag):\n",
    "                    addData(name_native_,p)\n",
    "                else:\n",
    "                    addData(name_native_,p)\n",
    "            except:\n",
    "                name_native_.append(np.nan)\n",
    "            \n",
    "        if ((testStr == \"Synonyms\") & (name_synon_Flag == False)):\n",
    "            name_synon_Flag = True\n",
    "            try:\n",
    "                if (engFlag):\n",
    "                    addData(name_synon_,p)\n",
    "                else:\n",
    "                    addData(name_synon_,p)\n",
    "            except:\n",
    "                name_synon_.append(np.nan)\n",
    "                \n",
    "                \n",
    "    #If any feature was missing from an entry, append NaN  \n",
    "    if (format_Flag == False):  \n",
    "        format_.append(np.nan)\n",
    "        \n",
    "    if (chap_Flag == False):  \n",
    "        chap_.append(np.nan)\n",
    "        \n",
    "    if (vol_Flag == False):  \n",
    "        vol_.append(np.nan)\n",
    "\n",
    "    if (status_Flag == False):  \n",
    "        status_.append(np.nan)\n",
    "    \n",
    "    if (start_Flag == False):  \n",
    "        start_.append(np.nan)\n",
    "    \n",
    "    if (end_Flag == False):  \n",
    "        end_.append(np.nan)\n",
    "    \n",
    "    if (avg_score_Flag == False):  \n",
    "        avg_score_.append(np.nan)\n",
    "    \n",
    "    if (mean_score_Flag == False):  \n",
    "        mean_score_.append(np.nan)\n",
    "    \n",
    "    if (pop_Flag == False):  \n",
    "        pop_.append(np.nan)\n",
    "    \n",
    "    if (favs_Flag == False):  \n",
    "        favs_.append(np.nan)\n",
    "    \n",
    "    if (source_Flag == False):  \n",
    "        source_.append(np.nan)\n",
    "    \n",
    "    if (genres_Flag == False):  \n",
    "        genres_.append(np.nan)\n",
    "    \n",
    "    if (name_romaj_Flag == False):  \n",
    "        name_romaj_.append(np.nan)\n",
    "    \n",
    "    if (name_eng_Flag == False):  \n",
    "        name_eng_.append(np.nan)\n",
    "    \n",
    "    if (name_native_Flag == False):  \n",
    "        name_native_.append(np.nan)\n",
    "\n",
    "    if (name_synon_Flag == False):  \n",
    "        name_synon_.append(np.nan)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if (start_Flag == True):\n",
    "        yeartext = start_[0]\n",
    "        release_year.append([int(s) for s in yeartext.split() if s.isdigit()][0])\n",
    "    else:\n",
    "        release_year.append(np.nan)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Handle appending of ctbar features\n",
    "    for t in range(len(ctbar)):\n",
    "        \n",
    "        ctstr = ctlabels[t].get_attribute('innerHTML')\n",
    "        \n",
    "        if ((ctstr == '10') & (rating_10_Flag == False)):\n",
    "            rating_10_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_10,ctbar[t])\n",
    "            except:\n",
    "                rating_10.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '20') & (rating_20_Flag == False)):\n",
    "            rating_20_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_20,ctbar[t])\n",
    "            except:\n",
    "                rating_20.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '30') & (rating_30_Flag == False)):\n",
    "            rating_30_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_30,ctbar[t])\n",
    "            except:\n",
    "                rating_30.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '40') & (rating_40_Flag == False)):\n",
    "            rating_40_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_40,ctbar[t])\n",
    "            except:\n",
    "                rating_40.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '50') & (rating_50_Flag == False)):\n",
    "            rating_50_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_50,ctbar[t])\n",
    "            except:\n",
    "                rating_50.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '60') & (rating_60_Flag == False)):\n",
    "            rating_60_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_60,ctbar[t])\n",
    "            except:\n",
    "                rating_60.append(np.nan)  \n",
    "                \n",
    "        if ((ctstr == '70') & (rating_70_Flag == False)):\n",
    "            rating_70_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_70,ctbar[t])\n",
    "            except:\n",
    "                rating_70.append(np.nan)\n",
    "                \n",
    "        if ((ctstr == '80') & (rating_80_Flag == False)):\n",
    "            rating_80_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_80,ctbar[t])\n",
    "            except:\n",
    "                rating_80.append(np.nan)\n",
    "              \n",
    "        if ((ctstr == '90') & (rating_90_Flag == False)):\n",
    "            rating_90_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_90,ctbar[t])\n",
    "            except:\n",
    "                rating_90.append(np.nan)\n",
    "              \n",
    "        if ((ctstr == '100') & (rating_100_Flag == False)):\n",
    "            rating_100_Flag = True\n",
    "            try:\n",
    "                addCTBar(rating_100,ctbar[t])\n",
    "            except:\n",
    "                rating_100.append(np.nan)    \n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    if (rating_10_Flag == False):\n",
    "        rating_10.append(np.nan)\n",
    "   \n",
    "    if (rating_20_Flag == False):\n",
    "        rating_20.append(np.nan)\n",
    "    \n",
    "    if (rating_30_Flag == False):\n",
    "        rating_30.append(np.nan)\n",
    "    \n",
    "    if (rating_40_Flag == False):\n",
    "        rating_40.append(np.nan)\n",
    "    \n",
    "    if (rating_50_Flag == False):\n",
    "        rating_50.append(np.nan)\n",
    "    \n",
    "    if (rating_60_Flag == False):\n",
    "        rating_60.append(np.nan)\n",
    "    \n",
    "    if (rating_70_Flag == False):\n",
    "        rating_70.append(np.nan)\n",
    "    \n",
    "    if (rating_80_Flag == False):\n",
    "        rating_80.append(np.nan)\n",
    "    \n",
    "    if (rating_90_Flag == False):\n",
    "        rating_90.append(np.nan)\n",
    "    \n",
    "    if (rating_100_Flag == False):\n",
    "        rating_100.append(np.nan)\n",
    "\n",
    "\n",
    "    \n",
    "    #Handle appending of rankings features\n",
    "    try:\n",
    "        addText(rated_rank,ranku[0])\n",
    "    except:\n",
    "        rated_rank.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        addText(popul_rank,ranku[1])\n",
    "    except:\n",
    "        popul_rank.append(np.nan)\n",
    "        \n",
    "    if (rated_rank[0] != np.nan):\n",
    "        rstr = rated_rank[0].split('#')\n",
    "        ratenum.append([int(sr) for sr in rstr[1].split() if sr.isdigit()][0])\n",
    "    else:\n",
    "        ratenum.append(np.nan)\n",
    "        \n",
    "    if (popul_rank[0] != np.nan):\n",
    "        pstr = popul_rank[0].split('#')\n",
    "        populnum.append([int(sp) for sp in pstr[1].split() if sp.isdigit()][0])\n",
    "    else:\n",
    "        populnum.append(np.nan)\n",
    "        \n",
    "    \n",
    "    #Handle appending of top 3 tags features\n",
    "    \n",
    "    try:\n",
    "        tag_one.append(taglist[0].text)\n",
    "    except:\n",
    "        tag_one.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        tag_two.append(taglist[1].text)\n",
    "    except:\n",
    "        tag_two.append(np.nan)\n",
    "        \n",
    "    try:\n",
    "        tag_thr.append(taglist[2].text)\n",
    "    except:\n",
    "        tag_thr.append(np.nan)\n",
    "        \n",
    "    #Handle appending of top 3 genres features\n",
    "    \n",
    "    try:\n",
    "        genArr = genres_[0].split('\\n')\n",
    "    except:\n",
    "        genArr = []\n",
    "        \n",
    "    try:\n",
    "        gen_one.append(genArr[0])\n",
    "    except:\n",
    "        gen_one.append(np.nan)\n",
    "    \n",
    "    try:    \n",
    "        gen_two.append(genArr[1])\n",
    "    except:\n",
    "        gen_two.append(np.nan)\n",
    "    \n",
    "    try:    \n",
    "        gen_thr.append(genArr[2])\n",
    "    except:\n",
    "        gen_thr.append(np.nan)\n",
    "    \n",
    "    try:\n",
    "        name_word_count.append(len(name_romaj_[0].split(' ')))\n",
    "    except:\n",
    "        name_word_count.append(np.nan)\n",
    "    \n",
    "    #Handle appending of relations features\n",
    "\n",
    "    try:\n",
    "        cell1_type.append(pcell[0].find_element(By.CLASS_NAME,\"content\").find_element(By.CLASS_NAME,\"info\").text)\n",
    "    except:\n",
    "        cell1_type.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        cell2_type.append(pcell[1].find_element(By.CLASS_NAME,\"content\").find_element(By.CLASS_NAME,\"info\").text)\n",
    "    except:\n",
    "        cell2_type.append(np.nan)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Handle determining if there is an anime, and what was its release date\n",
    "    try:\n",
    "        for r in pcell:\n",
    "            relations_types.append(r.find_element(By.CLASS_NAME,\"content\").find_element(By.CLASS_NAME,\"info\").text)\n",
    "              \n",
    "    except:\n",
    "        relations_types.append(np.nan)\n",
    "            \n",
    "    #Check if this has an anime\n",
    "    if (relations_types[0] != np.nan):\n",
    "        for rt in range(len(relations_types)):\n",
    "            if (anime_Flag == False):\n",
    "                anime_Flag = has_anime(relations_types[rt])\n",
    "                if (anime_Flag == True):\n",
    "                    rts = pcell[rt]\n",
    "                \n",
    "        if (anime_Flag == True):\n",
    "            anime_rls_date.append(anime_date(rts.find_element(By.CLASS_NAME,\"title\").get_attribute('href')))\n",
    "        else:\n",
    "            anime_rls_date.append(np.nan)\n",
    "        \n",
    "    \n",
    "    has_anime_.append(anime_Flag)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    links_.append(link)\n",
    "        \n",
    "    data = {\"Name Romaji\":name_romaj_,\n",
    "            \"Name Native\":name_native_,\n",
    "            \"Name English\":name_eng_,\n",
    "            \"Synonyms\":name_synon_,\n",
    "            \"Format\":format_,\n",
    "            \"Chapter Count\":chap_,\n",
    "            \"Volume Count\":vol_,\n",
    "            \"Status\":status_,\n",
    "            \"Start Date\":start_,\n",
    "            \"Start Year\":release_year,\n",
    "            \"End Date\":end_,\n",
    "            \"Average Score\":avg_score_,\n",
    "            \"Mean Score\":mean_score_,\n",
    "            \"Popularity\":pop_,\n",
    "            \"Favorites\":favs_,\n",
    "            \"Source\":source_,\n",
    "            \n",
    "            \"Genre_One\":gen_one,\n",
    "            \"Genre_Two\":gen_two,\n",
    "            \"Genre_Three\":gen_thr,\n",
    "            \n",
    "            \"Tag_One\":tag_one,\n",
    "            \"Tag_Two\":tag_two,\n",
    "            \"Tag_Three\":tag_thr,\n",
    "            \n",
    "            \"Rating 10\":rating_10,\n",
    "            \"Rating 20\":rating_20,\n",
    "            \"Rating 30\":rating_30,\n",
    "            \"Rating 40\":rating_40,\n",
    "            \"Rating 50\":rating_50,\n",
    "            \"Rating 60\":rating_60,\n",
    "            \"Rating 70\":rating_70,\n",
    "            \"Rating 80\":rating_80,\n",
    "            \"Rating 90\":rating_90,\n",
    "            \"Rating 100\":rating_100,\n",
    "            \n",
    "            \"Rating Rank\":rated_rank,\n",
    "            \"Rating Number\":ratenum,\n",
    "            \"Popularity Rank\":popul_rank,\n",
    "            \"Popularity Number\":populnum,\n",
    "            \n",
    "            \"Related 1 Type\":cell1_type,\n",
    "            \"Related 2 Type\":cell2_type,\n",
    "            \"Has Anime\":has_anime_,\n",
    "            \"Anime Release Date\":anime_rls_date,\n",
    "            \n",
    "            \"Name Word Count\":name_word_count,\n",
    "            \"Link\":links_,\n",
    "\n",
    "            }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f406fe4-8fa2-481a-8f02-2ac7259e45bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'find_element'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_256072\\2734696153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mraw_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_into_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#print(len(link_list))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_256072\\682770532.py\u001b[0m in \u001b[0;36mget_data_into_df\u001b[1;34m(link, tempdrive)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0manime_Flag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0manime_rls_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manime_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0manime_rls_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'find_element'"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "raw_data = get_data_into_df(link_list[0],driver)\n",
    "\n",
    "\n",
    "#print(len(link_list))\n",
    "\n",
    "for k in range(1,len(link_list)):\n",
    "    temp_df = get_data_into_df(link_list[k],driver)\n",
    "    raw_data = pd.concat([raw_data,temp_df])\n",
    "    \n",
    "    clear_output(wait=False) #clears the output\n",
    "    print('{} out of {}'.format(k,len(link_list)-1)) #prints completion status\n",
    "    \n",
    "    if (k % 25 == 0):\n",
    "        print('waiting 4 sec cause k % 25') #prints that you have to wait\n",
    "        time.sleep(4)\n",
    "\n",
    "#del raw_data['Unnamed: 0'] #deletes the wierd 'Unnamed: 0' column that is basically filled only with 0s\n",
    "\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1bf6c8-00d7-4fba-bfbc-934487252c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv('raw_data.csv')\n",
    "raw_data.to_excel('raw_data_exc.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4de3e-2d9f-4f82-990c-6b1484f3c222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"raw_data.csv\")\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953a124-e19c-4230-9b71-aec70496a56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dat_clean = dat.copy()\n",
    "dat_clean.dropna(inplace = True, how='all')\n",
    "dat_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0fc50132-0108-4b66-b92d-c5c9832285cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name Romaji</th>\n",
       "      <th>Name Native</th>\n",
       "      <th>Name English</th>\n",
       "      <th>Synonyms</th>\n",
       "      <th>Format</th>\n",
       "      <th>Chapter Count</th>\n",
       "      <th>Volume Count</th>\n",
       "      <th>Status</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Start Year</th>\n",
       "      <th>...</th>\n",
       "      <th>Rating Rank</th>\n",
       "      <th>Rating Number</th>\n",
       "      <th>Popularity Rank</th>\n",
       "      <th>Popularity Number</th>\n",
       "      <th>Related 1 Type</th>\n",
       "      <th>Related 2 Type</th>\n",
       "      <th>Has Anime</th>\n",
       "      <th>Anime Release Date</th>\n",
       "      <th>Name Word Count</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re:Zero kara Hajimeru Isekai Seikatsu</td>\n",
       "      <td>Re:ゼロから始める異世界生活</td>\n",
       "      <td>Re:ZERO -Starting Life in Another World-</td>\n",
       "      <td>ReZero\\nRe: Life in a different world from zer...</td>\n",
       "      <td>Light Novel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Releasing</td>\n",
       "      <td>Jan 24, 2014</td>\n",
       "      <td>2014</td>\n",
       "      <td>...</td>\n",
       "      <td>#12 Highest Rated All Time</td>\n",
       "      <td>12</td>\n",
       "      <td>#5 Most Popular All Time</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>https://anilist.co/manga/85737/ReZero-kara-Haj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name Romaji      Name Native  \\\n",
       "0  Re:Zero kara Hajimeru Isekai Seikatsu  Re:ゼロから始める異世界生活   \n",
       "\n",
       "                               Name English  \\\n",
       "0  Re:ZERO -Starting Life in Another World-   \n",
       "\n",
       "                                            Synonyms       Format  \\\n",
       "0  ReZero\\nRe: Life in a different world from zer...  Light Novel   \n",
       "\n",
       "   Chapter Count  Volume Count     Status    Start Date  Start Year  ...  \\\n",
       "0            NaN           NaN  Releasing  Jan 24, 2014        2014  ...   \n",
       "\n",
       "                  Rating Rank Rating Number           Popularity Rank  \\\n",
       "0  #12 Highest Rated All Time            12  #5 Most Popular All Time   \n",
       "\n",
       "  Popularity Number Related 1 Type Related 2 Type Has Anime  \\\n",
       "0                 5                                   False   \n",
       "\n",
       "  Anime Release Date Name Word Count  \\\n",
       "0                NaN               5   \n",
       "\n",
       "                                                Link  \n",
       "0  https://anilist.co/manga/85737/ReZero-kara-Haj...  \n",
       "\n",
       "[1 rows x 42 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downtodf = get_data_into_df(\"https://anilist.co/manga/85737/ReZero-kara-Hajimeru-Isekai-Seikatsu/\",driver)\n",
    "downtodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6426b-2c5b-41dc-8718-fa45392c6867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
